\section{Methods for Concept Profiling}

%Here we give a high-level description of the overall method which consists of two steps: 1) extraction of concepts and 2) further extraction of elemental concepts and composite concepts.
In this section we describe our methods for building concept profiles. The process involves two steps: first, given a learning module's text data we need to extract the salient phrases that represent concepts. Subsection \ref{extraction} explores one way of automatically extracting concept phrases from a module's text data when no clear list of concepts is provided such as the case for MOOC courses. The second step in the process is to rank the extracted concepts according to their Elementa/Composite score (hence forth referred to as EC Score).

\subsection{Concept Extraction}\label{extraction}

%Here, we describe our method for concept extraction. Can the neural network be applied here? 

%We could say that we just use existing methods for this step, but if there's anything interesting to say here, e.g., using NN, or leveraging book index as training data, we should say that. 

As we have stated in the Related Work section, the problem of extracting concept phrases from text is not a new one in and of itself. Several semi-supervised and unsupervised methods have been proposed. Autophrase \cite{} and TopMine \cite{} are two notable unsupervised methods for salient phrase mining. In our work, we take a slightly different approach using neural networks. The resulting extracted concepts using our neural network are demonstrably better quality with higher precision and completeness than the results from TopMine or Autophrase. %might need to back this up with results in the eval section

Since our work pertains specifically to educational applications, we leverage on type of unique text data ubiquitiously available for the vast majority of learning modules: textbooks. Whether a learning module is taught in a traditional class setting or offered to independent learners through MOOCs, the subjects of the vast majority of learning modules have probably been covered by some textbook. What makes textbooks particularly useful to us as opposed to other types of educational text data is that each textbook has an expertly curated, clean, and complete list of concept phrases covered in the textbook; namely the textbook's index. Using the text data and index list of phrases from a textbook, we train a neural network to automatically identify and label concept phrases in other types of educational text data which cover the same subject, such as MOOC lecture transcripts, and which do not have a predefined index. In section \ref{experiment_setup} we describe such a setup using two textbooks and four MOOCs which cover the same topics. In the rest of this section, we describe the design of the auto-indexing neural network we used.

%add old text
The concept phrase extraction task is given a text document, and asked to determine which words and phrases in the text represent concepts and which do not. For this task we use the raw text from our textbook data sets as documents, and use the index from each textbook as labels. This is quite similar to the NP Chunking problem, wherein we must determine which parts of the text are Noun Phrases. We use a basic IOB (Inside, Outside, Beginning) scheme for our chunking.
Our neural network is designed to produce a ``B'' tag for the first word in a keyphrase in the textbook's index and then an ``I'' tag for every word following the first word in the same keyphrase. If a word is not part of any keyphrase, then it is tagged with an ``O''.

We used a fairly simple LSTM network to perform the tagging. We split each dataset into 75\% train and 25\% test. We trained each model over 8 epochs. We used a word embedding dimension and a hidden state dimension of 32. We use a single LSTM layer and then an addition linear layer which maps the hidden state of the LSTM to the tag space. We then perform a softmax over our tags. Our prediction is the max over our different tags.
%add figure of NN setup


\subsection{Building the Concept Profile}

%Here we describe the proposed (new) methods for discovering the two kinds of concepts. 

%Since this is a new challenge, we should devote most of our effort here to improve the methods. We may also propose multiple strategies if possible. 

The intuition behind our method for ranking concepts according to their EC Score is the observation that in a learning module, new concepts are introduced using other more elemental concepts. For example, in Caclulus, the concept "derivative" can be introduced to students using concepts such as "function", "slope", and "tangent". Later on in Multivariabel Calculus, "differential" and "derivative" can be used to introduce the concept of "partial derivative" to students. In general, a learning module's Concept Profile follows a roughly hierarchical structure with more Elemental concepts being used to explain or introduce more Composite concepts on the EC Score scale. Figure \ref{concept_space} illustrates this roughly hierarchical layered clusters structure to the learning module's Concept Profile. Intuitively, we expect that the more Elemental a concept is, the more clusters it is a part of, whereas the more Composite a concept is, the less clusters it appears in. This makes sense because more Elemental concepts can be used to explain a wider range of concepts that more "specialized" Composite concepts. Using the above intuition as our working hypothesis, we design a roughly hierarchical clustering method called "Layered Fuzzy C-Means" to detect these layered concept clusters.
%add concept space figure

\subsubsection{Concept Embeddings}
An important part of any text clustering algorithm is getting good embedding vector representation for the data points. This step is especially important for us since we need concept phrase embeddings to accurately capture the context of each concept so that concepts that appear in close locality to each other and carry similar contexts may successfully be clustered together. Since this is very dependent on the learning module we are building the Concept Profile for, pre-trained word embeddings such as those from BERT \cite{} or pre-trained GloVe \cite{}, are not compatible with our application. Instead, we must use concept phrase embeddings that have been trained on the learning module text data itself.

Since we have already trained a bidirectional LSTM to detect concept keywords and phrases in the previous step, we can easily grab the "tagged" concepts' embeddings from the final hidden layer of the LSTM after training. This will give us for each concept phrase one 32 dimensional "forward" embedding vector and one 32 dimensional "backward" embedding vector. To capture the complete context of the concept phrase from both directions, we concatenated the two vectors into one 64 dimensional "bidirectional" embedding vector for each detected concept. We use this 64 dimensional vector in the following clustering step.

We found that using the bidirectional embedding vectors from our trained LSTM yields higher quality concept clusters than other commonly used word embedding methods such as Word2Vec \cite{}. It also does not present us the problem of how to combine individual word embeddings into multi-word concept phrase embeddings; and since different concepts might consist of different length phrases, simply concatenating word embeddings to form phrase embeddings is not feasable. Further work on obtaining high quality concept phrase embeddings is left as a future work direction.

\subsubsection{Layered Fuzzy C-Means}
Our Layered Fuzzy C-Means clustering algorithm follows a loosely hierarchical clustering scheme where each iteration or "layer" consists of a run of the Fuzzy C-Means algorithm. The Fuzzy C-Means algorith was first introduced by ... in 198.. \cite{} and later improved by .. \cite{}. It is the standard algorithm for fuzzy clustering; the counterpart to the well known K-Means \cite{}. Fuzzy clustering expresses cluster membership as a probability distribution thus allowing data points to potentially belong to multiple "overlapping" clusters if their cluster membership probability passes a certain threshold. This is important for our purpose since our working hypothesis is that a more Elemental concept would be used to explain other Composite concepts, thus it would make sense for the more Elemental concept to belong to multiple clusters representing the Composite concepts it helps explain. See Figure \ref{concept_space}.

The input for the Layered Fuzzy C-Means is: 1) $X$: a 64 by N matrix which holds the 64 dimensional concept embeddings of the learning module's N extracted concepts from the Concept Extraction step \ref{extraction}, 2) the parameter $INIT_CLUSTERS$ which is a function of $N$ which specifies the number of clusters in the initial layer, 3) and the parameters $min_p$ and $min_q$ which specify the probability threshold for cluster membership and the clustering quality threshold for retaining layers.

The Layered Fuzzy C-Means outputs: 1) a dictionary of layer cluster membership matrices:  $U = {i: U_{i} | for each layer i}$ where each $U_{i}$ is a $C_{i}$ by $N$ matrix where $C_{i}$ is the number of clusters in layer $i$, 2) a dictionary of layer quality indices: $Q = {i: q_{i} | for each layer i}$.

The first iteration of Layered Fuzzy C-Means runs the $skfuzzy$'s python library implementation of the Fuzzy C-Means algorithm $fcm()$ \cite{} on the data matrix $X$ with number of clusters initialized to $INIT_CLUSTERS$. The resulting membership probability matrix is saved to the dictionary $U$. For each subsequent iteration, the number of clusters $INIT_CLUSTERS$ is decremented by 1; the final iteration runs $fcm()$ with number of clusters equal to 1. Figure \ref{layered_fcm} details our implementation of the Layered Fuzzy C-Means.

\subsubsection{Postprocessing for Hard Cluster Membership}

\subsubsection{Pruning for Quality Layers}


\subsubsection{Computing the EC Score}

